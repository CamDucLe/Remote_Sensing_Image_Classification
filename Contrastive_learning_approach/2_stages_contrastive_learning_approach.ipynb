{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Check hardware + Drive Connection"
      ],
      "metadata": {
        "id": "n3pY4i9IwNVG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jacNRAYhwAdI"
      },
      "outputs": [],
      "source": [
        "! pip install tensorflow==2.9.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "drive.mount('/content/drive')\n",
        "print(\"tensorflow version: \", tf.__version__) # 2.9.0\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "_oyepN_DwSFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cat /proc/meminfo\n",
        "# !cat /proc/cpuinfo\n",
        "# ! ps"
      ],
      "metadata": {
        "id": "nLBmrCcOwT2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare dataset"
      ],
      "metadata": {
        "id": "wPFovpz-wZ1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! unrar x /content/drive/MyDrive/Dataset/NWPU-RESISC45.rar /content/\n",
        "import os \n",
        "print(len(os.listdir('/content/NWPU-RESISC45/')))\n",
        "print(len(os.listdir('/content/NWPU-RESISC45/airplane')))"
      ],
      "metadata": {
        "id": "Yp5EwhrBwc56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "# import random\n",
        "\n",
        "# input_dir = '/content/NWPU-RESISC45'\n",
        "# store_dir = '/content/dataset'\n",
        "\n",
        "# # check/create directory\n",
        "# if not os.path.exists(store_dir):\n",
        "#   print('==== Create Data Dir =====')\n",
        "#   os.makedirs(store_dir)\n",
        "\n",
        "# store_dir_train = os.path.join(store_dir, 'train')\n",
        "# if not os.path.exists(store_dir_train):\n",
        "#   print('==== Create Train Dir =====')\n",
        "#   os.makedirs(store_dir_train)\n",
        "\n",
        "# store_dir_test = os.path.join(store_dir, 'test')\n",
        "# if not os.path.exists(store_dir_test):\n",
        "#   print('==== Create Test Dir =====')\n",
        "#   os.makedirs(store_dir_test)\n",
        "\n",
        "# class_list = os.listdir(input_dir)  # Name of all classes \n",
        "# class_list.sort() # sort alphetically\n",
        "\n",
        "# for class_name in class_list:\n",
        "#   class_input_dir = os.path.abspath(os.path.join(input_dir, class_name))\n",
        "#   file_name_list = os.listdir(class_input_dir)\n",
        "#   file_name_list.sort()\n",
        "#   # file_name_random = np.random.permutation(range(len(file_name_list)))\n",
        "#   for i in range(len(file_name_list)):\n",
        "#     # file_name = file_name_list[file_name_random[i]]\n",
        "#     file_name = file_name_list[i]\n",
        "#     file_open = os.path.join(class_input_dir, file_name)\n",
        "#     org_img = Image.open(file_open)   # take out image\n",
        "#     org_img = org_img.resize((256,256)) # resize\n",
        "#     if i >= int(len(file_name_list)*0.8): # train set\n",
        "#       train_path = os.path.join(store_dir_train, file_name)\n",
        "#       org_img.save(train_path)\n",
        "#     else:                                   # test  set\n",
        "#       test_path = os.path.join(store_dir_test, file_name)\n",
        "#       org_img.save(test_path)\n",
        "\n",
        "\n",
        "# tr = os.listdir(store_dir_train)\n",
        "# te = os.listdir(store_dir_test)\n",
        "# print(len(tr), len(te), len(tr) + len(te))   \n",
        "\n",
        "# l = os.listdir('/content/dataset/train/')\n",
        "# l.sort()\n",
        "# print(l[0],l[139],l[140])\n",
        "\n",
        "# del l, tr,te,org_img,file_name,file_open,file_name_list,class_list,class_input_dir,train_path,test_path"
      ],
      "metadata": {
        "id": "yUm9SjfRwmOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "input_dir = '/content/NWPU-RESISC45'\n",
        "store_dir = '/content/dataset2'\n",
        "\n",
        "# check/create directory\n",
        "if not os.path.exists(store_dir):\n",
        "  print('==== Create Data Dir =====')\n",
        "  os.makedirs(store_dir)\n",
        "\n",
        "store_dir_train = os.path.join(store_dir, 'train')\n",
        "if not os.path.exists(store_dir_train):\n",
        "  print('==== Create Train Dir =====')\n",
        "  os.makedirs(store_dir_train)\n",
        "\n",
        "store_dir_test = os.path.join(store_dir, 'test')\n",
        "if not os.path.exists(store_dir_test):\n",
        "  print('==== Create Test Dir =====')\n",
        "  os.makedirs(store_dir_test)\n",
        "\n",
        "class_list = os.listdir(input_dir)  # Name of all classes \n",
        "class_list.sort() # sort alphetically\n",
        "\n",
        "for class_name in class_list:\n",
        "  class_train_dir = os.path.abspath(os.path.join(store_dir_train, class_name))\n",
        "  os.makedirs(class_train_dir)\n",
        "  class_test_dir = os.path.abspath(os.path.join(store_dir_test, class_name))\n",
        "  os.makedirs(class_test_dir)\n",
        "\n",
        "  class_input_dir = os.path.abspath(os.path.join(input_dir, class_name))\n",
        "  file_name_list = os.listdir(class_input_dir)\n",
        "  file_name_list.sort()\n",
        "  # file_name_random = np.random.permutation(range(len(file_name_list)))\n",
        "\n",
        "  for i in range(len(file_name_list)):\n",
        "    # file_name = file_name_list[file_name_random[i]]\n",
        "    file_name = file_name_list[i]\n",
        "    file_open = os.path.join(class_input_dir, file_name)\n",
        "    org_img = Image.open(file_open)   # take out image\n",
        "    org_img = org_img.resize((256,256)) # resize\n",
        "    if i >= int(len(file_name_list)*0.8): # train set\n",
        "      train_path = os.path.join(class_train_dir, file_name)\n",
        "      org_img.save(train_path)\n",
        "    else:                                   # test  set\n",
        "      test_path = os.path.join(class_test_dir, file_name)\n",
        "      org_img.save(test_path)\n",
        "\n",
        "print(len(os.listdir('/content/dataset2/train/')))\n",
        "print(len(os.listdir('/content/dataset2/test/')))\n",
        "print(len(os.listdir('/content/dataset2/train/airplane')))\n",
        "print(len(os.listdir('/content/dataset2/test/airplane')))\n",
        "l = os.listdir('/content/dataset2/train/airplane')\n",
        "l.sort()\n",
        "print(l[0],l[-1])\n",
        "del l,org_img,file_name,file_open,file_name_list,class_list,class_input_dir,train_path,test_path,class_train_dir,class_test_dir"
      ],
      "metadata": {
        "id": "1XcpA_Enwk-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator Phase 1"
      ],
      "metadata": {
        "id": "E9jShuTSwfnB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper-parameter.py"
      ],
      "metadata": {
        "id": "eVfTMNqow16O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class hypara(object):\n",
        "  def __init__(self):\n",
        "    self.label_dict  = dict(    airplane              = 0,\n",
        "                                airport               = 1,\n",
        "                                baseball_diamond      = 2,\n",
        "                                basketball_court      = 3,\n",
        "                                beach                 = 4,\n",
        "                                bridge                = 5,\n",
        "                                chaparral             = 6,\n",
        "                                church                = 7,\n",
        "                                circular_farmland     = 8,\n",
        "                                cloud                 = 9,\n",
        "                                commercial_area       = 10,\n",
        "                                dense_residential     = 11,\n",
        "                                desert                = 12,\n",
        "                                forest                = 13,\n",
        "                                freeway               = 14,\n",
        "                                golf_course           = 15,\n",
        "                                ground_track_field    = 16,\n",
        "                                harbor                = 17,\n",
        "                                industrial_area       = 18,\n",
        "                                intersection          = 19,\n",
        "                                island                = 20,\n",
        "                                lake                  = 21,\n",
        "                                meadow                = 22,\n",
        "                                medium_residential    = 23,\n",
        "                                mobile_home_park      = 24,\n",
        "                                mountain              = 25,\n",
        "                                overpass              = 26,\n",
        "                                palace                = 27,\n",
        "                                parking_lot           = 28,\n",
        "                                railway               = 29,\n",
        "                                railway_station       = 30,\n",
        "                                rectangular_farmland  = 31,\n",
        "                                river                 = 32,\n",
        "                                roundabout            = 33,\n",
        "                                runway                = 34,\n",
        "                                sea_ice               = 35,\n",
        "                                ship                  = 36,\n",
        "                                snowberg              = 37,\n",
        "                                sparse_residential    = 38,\n",
        "                                stadium               = 39,\n",
        "                                storage_tank          = 40,\n",
        "                                tennis_court          = 41,\n",
        "                                terrace               = 42,\n",
        "                                thermal_power_station = 43,\n",
        "                                wetland               = 44 )\n",
        "\n",
        "        #---- Para for generator and training\n",
        "    self.nT_aud        = 256    #Time resolution\n",
        "    self.nF_aud        = 256    #Frequency resolution\n",
        "    self.nC_aud        = 3      #Channel resolution\n",
        "    self.eps           = np.spacing(1)\n",
        "    self.batch_size    = 6 # \n",
        "    self.start_batch   = 0\n",
        "    self.learning_rate = 4e-4\n",
        "    self.is_aug        = True\n",
        "    self.check_every   = 200\n",
        "    self.class_num     = 45\n",
        "    self.epoch_num     = 72"
      ],
      "metadata": {
        "id": "ugZEL-1LwyF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contrastive generator for self-supervised( take image from dataset2/train) - Phase 1"
      ],
      "metadata": {
        "id": "y1GluuMAw93m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageFilter, ImageEnhance\n",
        "import os\n",
        "\n",
        "class ContrastiveGenerator(object):\n",
        "  def __init__(self, img_dir, batch_size=9):  \n",
        "    self.img_dir       = img_dir # 'content/dataset_2/train/'\n",
        "    self.batch_size    = batch_size\n",
        "    self.class_num     = hypara().class_num\n",
        "    self.label_dict    = hypara().label_dict\n",
        "    \n",
        "  def get_num_classes(self):\n",
        "    return len(os.listdir(self.img_dir))\n",
        "\n",
        "  def get_imgs_of_class(self,cls):\n",
        "    return os.listdir(os.path.join(self.img_dir,cls))\n",
        "\n",
        "  def get_batch (self, idx_num, class_list): # TODO check \n",
        "    if self.batch_size != len(class_list):\n",
        "      raise ValueError('batch_size is not equal !')\n",
        "    \n",
        "    x_1 = np.zeros((self.batch_size,256,256,3), dtype=np.float32)\n",
        "    x_2 = np.zeros((self.batch_size,256,256,3), dtype=np.float32)\n",
        "    i = 0\n",
        "    for c in class_list: # class_list can be considered as batch_size\n",
        "      file_path     = os.path.join(self.img_dir, c)\n",
        "      file_list     = self.get_imgs_of_class(c)\n",
        "\n",
        "      file_name_1   = file_list[idx_num]\n",
        "      file_name_2   = file_list[random.randrange(140)]\n",
        "\n",
        "      file_open_1   = os.path.join(file_path, file_name_1)\n",
        "      file_open_2   = os.path.join(file_path, file_name_2)\n",
        "     \n",
        "      img_1         = Image.open(file_open_1) \n",
        "      img_2         = Image.open(file_open_2) \n",
        "      \n",
        "      img_1         = self.augmentate(img_1)\n",
        "      img_2         = self.augmentate(img_2) \n",
        "\n",
        "      img_1 = np.asarray(img_1).astype(np.float32) # 256x256x3\n",
        "      img_2 = np.asarray(img_2).astype(np.float32) # 256x256x3\n",
        "\n",
        "      # img_1 /= 255\n",
        "      # img_2 /= 255\n",
        "          \n",
        "      x_1[i,:,:,:] = img_1\n",
        "      x_2[i,:,:,:] = img_2\n",
        "\n",
        "      i += 1\n",
        "\n",
        "    x_1 = tf.convert_to_tensor(x_1, dtype=tf.float32)\n",
        "    x_2 = tf.convert_to_tensor(x_2, dtype=tf.float32)\n",
        "    return x_1, x_2\n",
        "\n",
        "  def augmentate(self, one_image, flag=False): #---- data augmentation\n",
        "    if np.random.uniform() > 0.4: # not augmentation\n",
        "      return one_image\n",
        "\n",
        "    if np.random.uniform() > 0.5: # rotate\n",
        "      angle = random.choice([15,90,180,270])\n",
        "      one_image  = one_image.rotate(angle)\n",
        "    \n",
        "    if np.random.uniform() > 0.5: # crop\n",
        "      rand = np.random.randint(0,15)\n",
        "      one_image  = one_image.crop((rand,rand,256-rand,256-rand))\n",
        "      one_image  = one_image.resize((256,256), resample=Image.BILINEAR)\n",
        "    \n",
        "    rand = np.random.uniform()\n",
        "    if rand > 0.5: # change color channel\n",
        "      r, g, b = one_image.split()\n",
        "      tup =  (b, r, g) if rand > 0.75 else (g, b, r)\n",
        "      one_image = Image.merge(\"RGB\", tup)\n",
        "    \n",
        "    if np.random.uniform() > 0.5: # change brightness\n",
        "      one_image = one_image.point(lambda i: i * 1.27 if i*1.27 <= 255 else 255)\n",
        "    \n",
        "    if np.random.uniform() > 0.5: # add noise\n",
        "        one_image = one_image.point(lambda i: i + np.random.randint(-4,4)) \n",
        "\n",
        "    rand = np.random.uniform() \n",
        "    if rand > 0.75: # change contrast/sharpness/blur\n",
        "      enhancer = ImageEnhance.Sharpness(one_image)\n",
        "      one_image = enhancer.enhance(2.73)\n",
        "    elif rand > 0.7: \n",
        "      one_image = one_image.filter(ImageFilter.BLUR)\n",
        "    elif rand > 0.45:\n",
        "      enhancer = ImageEnhance.Contrast(one_image)\n",
        "      one_image = enhancer.enhance(2.27)\n",
        "\n",
        "    return one_image\n",
        "\n",
        "img_dir = '/content/dataset2/train/'\n",
        "generator = ContrastiveGenerator(img_dir=img_dir, batch_size=5)\n",
        "\n",
        "print(generator.get_num_classes())\n",
        "print(len(generator.get_imgs_of_class('roundabout')))\n",
        "\n",
        "cls = ['chaparral', 'runway', 'sea_ice', 'intersection', 'desert']\n",
        "x1, x2 = generator.get_batch(0,cls)\n",
        "print(x1.shape,x2.shape)"
      ],
      "metadata": {
        "id": "p-EoML_dw7ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.fromarray((x1[0].numpy()).astype(np.uint8), 'RGB') # *255\n",
        "img.show()\n",
        "img = Image.fromarray((x2[0].numpy()).astype(np.uint8), 'RGB')\n",
        "img.show()\n",
        "img = Image.fromarray((x1[1].numpy()).astype(np.uint8), 'RGB')\n",
        "img.show()\n",
        "img = Image.fromarray((x2[1].numpy()).astype(np.uint8), 'RGB')\n",
        "img.show()\n",
        "img = Image.fromarray((x1[2].numpy()).astype(np.uint8), 'RGB')\n",
        "img.show()\n",
        "img = Image.fromarray((x2[2].numpy()).astype(np.uint8), 'RGB')\n",
        "img.show()\n",
        "\n",
        "del img, x1, x2, generator, img_dir, cls"
      ],
      "metadata": {
        "id": "Rv8cE4yKxDKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contrastive loss + model for phase 1"
      ],
      "metadata": {
        "id": "2AavHpyYxHBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class SimCLRLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self, temperature=0.27, rate=0.72, name='SimCLRLoss', **kwargs):\n",
        "    super(SimCLRLoss, self).__init__(name=name, **kwargs)\n",
        "    self.temperature   = temperature\n",
        "    self.rate          = rate\n",
        "    self.cosine_sim    = tf.keras.losses.CosineSimilarity(axis=-1, reduction=tf.keras.losses.Reduction.NONE)\n",
        "    self.cross_entropy = tf.keras.losses.CategoricalCrossentropy(axis=-1, reduction=tf.keras.losses.Reduction.NONE)\n",
        "    \n",
        "  # @tf.function\n",
        "  def call(self, z1, z2):\n",
        "    batch_size, n_dim = z1.shape\n",
        "\n",
        "    # Compute Distance loss\n",
        "    z1_soft = tf.keras.activations.softmax(z1, axis=-1)       # (Bx1280) \n",
        "    z2_soft = tf.keras.activations.softmax(z2, axis=-1)       # (Bx1280)\n",
        "    print(z1_soft,'\\n',z2_soft) \n",
        "    distance = tf.norm(z1_soft - z2_soft, ord='euclidean')           # (B) \n",
        "    mean_distance = tf.sqrt(tf.reduce_mean(distance))         # () -> scalar\n",
        "    # print('dis: ', mean_distance)\n",
        "    tf.debugging.check_numerics(mean_distance.numpy(), 'Distance contains NaN values.')\n",
        "\n",
        "    # Compute Consine Similarity loss\n",
        "    z = tf.concat((z1, z2), 0)\n",
        "\n",
        "    sim_ij      = - self.cosine_sim(z[:batch_size], z[batch_size:])     # (B)  -> batch_size pair\n",
        "    sim_ji      = - self.cosine_sim(z[batch_size:], z[:batch_size])     # (B)  -> batch_size pair\n",
        "    sim_pos     = tf.concat((sim_ij,sim_ji), axis=0)                    # (2B) -> 2*batch_size positive pair\n",
        "    numerator   = tf.math.exp(sim_pos / self.temperature)               # (2B) -> 2*batch_size positive pair\n",
        "\n",
        "    sim_neg     = - self.cosine_sim(tf.expand_dims(z, 1), z)            # sim (Bx1xE, BxE) -> (2Bx2B)\n",
        "    mask        = 1 - tf.eye(2*batch_size, dtype=tf.float32)            # (2Bx2B)\n",
        "    sim_neg     = mask * tf.math.exp(sim_neg / self.temperature)        # (2Bx2B)\n",
        "    denominator = tf.math.reduce_sum(sim_neg, axis=-1)                  # (2B) \n",
        "\n",
        "    mean_cosine_similarity = tf.reduce_mean(- tf.math.log(numerator / denominator))       # () -> scalar\n",
        "    tf.debugging.check_numerics(mean_cosine_similarity.numpy(), 'Cosine contains NaN values.')\n",
        "    # print('cos: ', mean_cosine_similarity)\n",
        "\n",
        "    # Compute total loss with associated rate\n",
        "    total_loss = (1-self.rate)*mean_distance + self.rate*mean_cosine_similarity \n",
        "    # print('total: ',total_loss)\n",
        "    tf.debugging.check_numerics(total_loss.numpy(), 'Total contains NaN values.')\n",
        "    return total_loss\n",
        "\n",
        "loss = SimCLRLoss(rate=0)\n",
        "h1 = tf.constant([[1.,0,0.5,0.15,0.4,0.8]])\n",
        "h2 = tf.constant([[1.,0,0.5,0.15,0.4,0.8]])\n",
        "# h2 = tf.constant([[0.1,0.2,0.6,0.25,0.1,0.5]])\n",
        "# h2 = tf.constant([[300,300.2,300.6,300.25,0.1,300.5], [300.,300,100.25,10.55,40.4,50.1]])\n",
        "print(loss.call(h1,h2))\n",
        "del loss, h1,h2"
      ],
      "metadata": {
        "id": "Zp4CoZuuxI9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Concatenate, Flatten, MultiHeadAttention, Add, Average, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.applications import MobileNet, EfficientNetB0\n",
        "from tensorflow.keras.activations import sigmoid\n",
        "import numpy as np \n",
        "import os\n",
        "\n",
        "def trippleAttention(x): # 8x8xc\n",
        "  ## TA - Tripple Attention\n",
        "  c = x.shape[-1]\n",
        "    # channel\n",
        "  tl1 = tf.math.reduce_mean(x, axis=-1) + tf.math.reduce_max(x, axis=-1)# 8x8        \n",
        "  tl1 = MultiHeadAttention(num_heads=16, key_dim=8)(tl1, tl1)           # 8x8 \n",
        "  tl1 = sigmoid(tl1)            # 8x8\n",
        "  tl1 = Reshape((8,8,1))(tl1)   # 8x8x1\n",
        "  tl1 = x * tl1                 # 8x8xc * 8x8x1 -> 8x8xc\n",
        "    # width\n",
        "  tl2 = tf.math.reduce_mean(x, axis=-2) + tf.math.reduce_max(x, axis=-2)# 8xc\n",
        "  tl2 = MultiHeadAttention(num_heads=16, key_dim=8)(tl2, tl2)          # 8xc\n",
        "  tl2 = sigmoid(tl2)            # 8xcx1\n",
        "  tl2 = Reshape((8,1,c))(tl2)   # 8x1xc\n",
        "  tl2 = x * tl2                 # 8x8xc * 8x1xc -> 8x8xc\n",
        "    # height\n",
        "  tl3 = tf.math.reduce_mean(x, axis=-3) + tf.math.reduce_max(x, axis=-3)# 8xc\n",
        "  tl3 = MultiHeadAttention(num_heads=16, key_dim=8)(tl3, tl3)          # 8xc\n",
        "  tl3 = sigmoid(tl3)            # 8xcx1\n",
        "  tl3 = Reshape((1,8,c))(tl3)   # 8x1xc\n",
        "  tl3 = x * tl3                 # 8x8xc * 1x8xc -> 8x8xc\n",
        "    # average \n",
        "  t = Average()([tl1, tl2, tl3]) # 8x8xc\n",
        "  t = GlobalAveragePooling2D(keepdims=False)(t) #channel\n",
        "  return t # c\n",
        "\n",
        "# Define the encoder network\n",
        "def get_encoder():\n",
        "  base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(256,256,3))\n",
        "\n",
        "  block7_x = base_model.output                           \n",
        "  block6_x = base_model.get_layer('block6d_add').output  \n",
        "  block5_x = base_model.get_layer('block5c_add').output  \n",
        "  \n",
        "  block6_x = Conv2D(filters=1280, kernel_size=1, strides=1)(block6_x) \n",
        "  block5_x = Conv2D(filters=1280, kernel_size=2, strides=2)(block5_x) \n",
        "  \n",
        "  block7_x = trippleAttention(block7_x)\n",
        "  block6_x = trippleAttention(block6_x)\n",
        "  block5_x = trippleAttention(block5_x)\n",
        "  x = block5_x + block6_x + block7_x\n",
        "\n",
        "  return Model(base_model.input, x)\n",
        "\n",
        "# Define the SimCLR model\n",
        "def get_simclr(encoder):\n",
        "    inputs1 = tf.keras.Input(shape=(256, 256, 3))\n",
        "    inputs2 = tf.keras.Input(shape=(256, 256, 3))\n",
        "    h1 = encoder(inputs1)\n",
        "    h2 = encoder(inputs2)\n",
        "    return Model([inputs1, inputs2], [h1, h2])\n",
        "\n",
        "  # Initialize the encoder and the SimCLR model\n",
        "if os.path.exists('/content/drive/MyDrive/RSIC/NWPU-RESISC45/simclr_model.h5'):\n",
        "  print('loading model !')\n",
        "  simclr = tf.keras.models.load_model('/content/drive/MyDrive/RSIC/NWPU-RESISC45/simclr_model.h5', custom_objects={'SimCLRLoss':SimCLRLoss}, compile = True)\n",
        "  simclr.summary()\n",
        "else:\n",
        "  print('creating model !')\n",
        "  simclr = get_simclr(get_encoder())\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate=5e-3)\n",
        "  simclr.compile(optimizer, loss=SimCLRLoss(rate=0.6), metrics=[])\n",
        "  simclr.summary()\n"
      ],
      "metadata": {
        "id": "Knd-2MSlxNrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Self-supervised model - Phase 1"
      ],
      "metadata": {
        "id": "qjX038EbxXRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "  if epoch < 50:\n",
        "    return 5e-3 - (epoch//10)*1e-3\n",
        "  elif epoch <= 273 and (epoch%5==0):\n",
        "    return lr * (0.9) \n",
        "  elif epoch > 273:\n",
        "    return 3e-6\n",
        "  else:\n",
        "    return lr\n",
        "  \n",
        "BATCH_SIZE = 15 # 3 or 5 or 9 or 15 or 45\n",
        "IMG_DIR = '/content/dataset2/train/'\n",
        "loss_list = []\n",
        "best_loss = 187.7\n",
        "current_epoch = 143\n",
        "generator = ContrastiveGenerator(img_dir=IMG_DIR, batch_size=BATCH_SIZE)\n",
        "\n",
        "for epoch in range(current_epoch, 727):\n",
        "  print('\\n ============= Epoch: ', epoch,'===============')\n",
        "  s = datetime.now()\n",
        "  epoch_loss = 0\n",
        "  label_dict = hypara().label_dict\n",
        "  class_list = list(label_dict.keys())\n",
        "  random.shuffle(class_list)\n",
        "  if epoch == 143:\n",
        "    simclr.optimizer.learning_rate = 0.0001853\n",
        "  else:  \n",
        "    simclr.optimizer.learning_rate = lr_schedule(epoch, simclr.optimizer.learning_rate.numpy())\n",
        "  print('learning rate: ', simclr.optimizer.learning_rate)\n",
        "\n",
        "  for i in range(int(45 / BATCH_SIZE)):\n",
        "    for n_batch in range(140):\n",
        "      x1, x2 = generator.get_batch(n_batch, class_list[i*BATCH_SIZE:(i+1)*BATCH_SIZE]) # return 2 batches of images, each batch contain B images from B class\n",
        "      with tf.GradientTape() as tape:\n",
        "        h1, h2 = simclr([x1, x2])\n",
        "        # print(h1.shape,h2.shape)\n",
        "        loss = simclr.loss(h1, h2)\n",
        "        epoch_loss += loss.numpy()\n",
        "        # loss_list.append(loss.numpy())\n",
        "        grads = tape.gradient(loss, simclr.trainable_variables) \n",
        "        tf.debugging.check_numerics(grads[0], 'grad contains NaN values.')\n",
        "        simclr.optimizer.apply_gradients(zip(grads, simclr.trainable_variables))    \n",
        "    \n",
        "    print('1/3 (33.33% further completed): ', i*33.33, ' - Loss: ', loss.numpy())\n",
        "  \n",
        "  print('epoch loss:  ', epoch_loss, ';  best loss: ', best_loss)\n",
        "  \n",
        "  if epoch < 111 or epoch_loss < best_loss:\n",
        "    best_loss = epoch_loss\n",
        "    simclr.save('/content/drive/MyDrive/RSIC/NWPU-RESISC45/simclr_model.h5')\n",
        "    with open(os.path.join('/content/drive/MyDrive/RSIC/NWPU-RESISC45/',\"train_log.txt\"), \"a\") as text_file:\n",
        "      text_file.write(\"Save model at Epoch: {}; Loss: {}\\n\".format(epoch, best_loss))\n",
        "    print(' --- save complete ---')\n",
        "\n",
        "  print('epoch training time: ', datetime.now()-s, '\\n')\n"
      ],
      "metadata": {
        "id": "pyh5orQVxdrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(grads[0].shape)\n",
        "# print(loss)\n",
        "# print(tf.reduce_min(simclr.trainable_variables[0]))\n",
        "# print(tf.reduce_max(simclr.trainable_variables[0]))\n",
        "# print(simclr.optimizer)"
      ],
      "metadata": {
        "id": "AXcrGlgDxoF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install numba\n",
        "# # clear gpu memory\n",
        "# from numba import cuda \n",
        "# device = cuda.get_current_device()\n",
        "# device.reset()\n",
        "# !nvidia-smi "
      ],
      "metadata": {
        "id": "TYCOW_T9xssA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer backbone for supervised learning for Phase 2"
      ],
      "metadata": {
        "id": "isZ50Nu3xw-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class SimCLRLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self, temperature=0.27, rate=0.72, name='SimCLRLoss', **kwargs):\n",
        "    super(SimCLRLoss, self).__init__(name=name, **kwargs)\n",
        "    self.temperature   = temperature\n",
        "    self.rate          = rate\n",
        "    self.cosine_sim    = tf.keras.losses.CosineSimilarity(axis=-1, reduction=tf.keras.losses.Reduction.NONE)\n",
        "    self.cross_entropy = tf.keras.losses.CategoricalCrossentropy(axis=-1, reduction=tf.keras.losses.Reduction.NONE)\n",
        "    \n",
        "  # @tf.function\n",
        "  def call(self, z1, z2):\n",
        "    batch_size, n_dim = z1.shape\n",
        "\n",
        "    # Compute Distance loss\n",
        "    z1_soft = tf.keras.activations.softmax(z1, axis=-1)       # (Bx1280) \n",
        "    z2_soft = tf.keras.activations.softmax(z2, axis=-1)       # (Bx1280) \n",
        "    distance = self.cross_entropy(z1_soft, z2_soft)           # (B) \n",
        "    mean_distance = tf.sqrt(tf.reduce_mean(distance))         # () -> scalar\n",
        "    # print('dis: ', mean_distance)\n",
        "    tf.debugging.check_numerics(mean_distance.numpy(), 'Distance contains NaN values.')\n",
        "\n",
        "    # Compute Consine Similarity loss\n",
        "    z = tf.concat((z1, z2), 0)\n",
        "\n",
        "    sim_ij      = - self.cosine_sim(z[:batch_size], z[batch_size:])     # (B)  -> batch_size pair\n",
        "    sim_ji      = - self.cosine_sim(z[batch_size:], z[:batch_size])     # (B)  -> batch_size pair\n",
        "    sim_pos     = tf.concat((sim_ij,sim_ji), axis=0)                    # (2B) -> 2*batch_size positive pair\n",
        "    numerator   = tf.math.exp(sim_pos / self.temperature)               # (2B) -> 2*batch_size positive pair\n",
        "    # print(numerator)\n",
        "    sim_neg     = - self.cosine_sim(tf.expand_dims(z, 1), z)            # sim (Bx1xE, BxE) -> (2Bx2B)\n",
        "    mask        = 1 - tf.eye(2*batch_size, dtype=tf.float32)            # (2Bx2B)\n",
        "    sim_neg     = mask * tf.math.exp(sim_neg / self.temperature)        # (2Bx2B)\n",
        "    denominator = tf.math.reduce_sum(sim_neg, axis=-1)                  # (2B) \n",
        "    # print(denominator)\n",
        "    mean_cosine_similarity = tf.reduce_mean(- tf.math.log(numerator / denominator))       # () -> scalar\n",
        "    tf.debugging.check_numerics(mean_cosine_similarity.numpy(), 'Cosine contains NaN values.')\n",
        "    # print('cos: ', mean_cosine_similarity)\n",
        "\n",
        "    # Compute total loss with associated rate\n",
        "    total_loss = (1-self.rate)*mean_distance + self.rate*mean_cosine_similarity \n",
        "    # print('total: ',total_loss)\n",
        "    tf.debugging.check_numerics(total_loss.numpy(), 'Total contains NaN values.')\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "dYq6Fliqx6s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/RSIC/NWPU-RESISC45/simclr_model.h5', custom_objects={'SimCLRLoss':SimCLRLoss}, compile = True)\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "id": "33uamaLkx8if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy pre-trained encoder\n",
        "for layer in loaded_model.layers:\n",
        "  if layer.name =='model':\n",
        "    pre_trained_encoder = layer\n",
        "    break"
      ],
      "metadata": {
        "id": "PDz9Ngo-x9v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Conv2D, Activation, Dropout, Flatten, Input, Dense, MultiHeadAttention\n",
        "from tensorflow.keras.layers import Add, Average, Concatenate,Reshape, multiply, Permute, Lambda\n",
        "from tensorflow.keras import initializers, regularizers\n",
        "from tensorflow.keras.activations import sigmoid\n",
        "\n",
        "\n",
        "def trippleAttention(x): # 8x8xc\n",
        "  ## TA - Tripple Attention\n",
        "  c = x.shape[-1]\n",
        "    # channel\n",
        "  tl1 = tf.math.reduce_mean(x, axis=-1) + tf.math.reduce_max(x, axis=-1)# 8x8        \n",
        "  tl1 = MultiHeadAttention(num_heads=16, key_dim=8)(tl1, tl1)           # 8x8 \n",
        "  tl1 = sigmoid(tl1)            # 8x8\n",
        "  tl1 = Reshape((8,8,1))(tl1)   # 8x8x1\n",
        "  tl1 = x * tl1                 # 8x8xc * 8x8x1 -> 8x8xc\n",
        "    # width\n",
        "  tl2 = tf.math.reduce_mean(x, axis=-2) + tf.math.reduce_max(x, axis=-2)# 8xc\n",
        "  tl2 = MultiHeadAttention(num_heads=16, key_dim=8)(tl2, tl2)          # 8xc\n",
        "  tl2 = sigmoid(tl2)            # 8xcx1\n",
        "  tl2 = Reshape((8,1,c))(tl2)   # 8x1xc\n",
        "  tl2 = x * tl2                 # 8x8xc * 8x1xc -> 8x8xc\n",
        "    # height\n",
        "  tl3 = tf.math.reduce_mean(x, axis=-3) + tf.math.reduce_max(x, axis=-3)# 8xc\n",
        "  tl3 = MultiHeadAttention(num_heads=16, key_dim=8)(tl3, tl3)          # 8xc\n",
        "  tl3 = sigmoid(tl3)            # 8xcx1\n",
        "  tl3 = Reshape((1,8,c))(tl3)   # 8x1xc\n",
        "  tl3 = x * tl3                 # 8x8xc * 1x8xc -> 8x8xc\n",
        "    # average \n",
        "  t = Average()([tl1, tl2, tl3]) # 8x8xc\n",
        "  t = GlobalAveragePooling2D(keepdims=False)(t) #channel\n",
        "  return t # c\n",
        "\n",
        "def get_encoder():\n",
        "  base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(256,256,3))\n",
        "\n",
        "  block7_x = base_model.output                           \n",
        "  block6_x = base_model.get_layer('block6d_add').output  \n",
        "  block5_x = base_model.get_layer('block5c_add').output  \n",
        "  \n",
        "  block6_x = Conv2D(filters=1280, kernel_size=1, strides=1)(block6_x) \n",
        "  block5_x = Conv2D(filters=1280, kernel_size=2, strides=2)(block5_x) \n",
        "  \n",
        "  block7_x = trippleAttention(block7_x)\n",
        "  block6_x = trippleAttention(block6_x)\n",
        "  block5_x = trippleAttention(block5_x)\n",
        "  \n",
        "  x = block5_x + block6_x + block7_x\n",
        "  return Model(base_model.input, x)\n",
        "\n",
        "# create full model\n",
        "def get_cls_model():\n",
        "  base_encoder = get_encoder()\n",
        "  base_encoder.set_weights(pre_trained_encoder.get_weights()) \n",
        "  base_encoder.trainable = True # False\n",
        "  \n",
        "  x = Dense(512, \n",
        "                    activation='relu',\n",
        "                    kernel_initializer=initializers.TruncatedNormal(mean=0.0,stddev=0.1),\n",
        "                    kernel_regularizer=regularizers.l2(1e-5),\n",
        "                    bias_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.1),\n",
        "                    bias_regularizer=regularizers.l2(1e-5)\n",
        "                    )(base_encoder.output)\n",
        "  x = Dropout(0.2)(x)\n",
        "  predictions = Dense(45, \n",
        "                        activation='softmax',\n",
        "                        kernel_initializer=initializers.TruncatedNormal(mean=0.0,stddev=0.1),\n",
        "                        kernel_regularizer=regularizers.l2(1e-5),\n",
        "                        bias_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.1),\n",
        "                        bias_regularizer=regularizers.l2(1e-5)\n",
        "                        )(x)\n",
        "\n",
        "  model = Model(inputs=base_encoder.input, outputs=predictions)\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=1e-4) # \n",
        "  model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=[\"accuracy\"])   \n",
        "  return model\n",
        "\n",
        "if os.path.exists('/content/drive/MyDrive/RSIC/NWPU-RESISC45/effb0_contrastive_2/contrastive_model.h5'):\n",
        "  print('loading model !')\n",
        "  model = tf.keras.models.load_model('/content/drive/MyDrive/RSIC/NWPU-RESISC45/effb0_contrastive_2/contrastive_model.h5')\n",
        "  print(model.optimizer.learning_rate)\n",
        "  # model.summary()\n",
        "else:\n",
        "  print('creating model !')\n",
        "  model = get_cls_model()\n",
        "  model.summary()\n"
      ],
      "metadata": {
        "id": "47SQ5yvIyAK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator Phase 2"
      ],
      "metadata": {
        "id": "ZiGhVuy7yOSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyper-parameter.py"
      ],
      "metadata": {
        "id": "tHnmz5iiyYK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class hypara(object):\n",
        "  def __init__(self):\n",
        "    self.label_dict  = dict(    airplane              = 0,\n",
        "                                airport               = 1,\n",
        "                                baseball_diamond      = 2,\n",
        "                                basketball_court      = 3,\n",
        "                                beach                 = 4,\n",
        "                                bridge                = 5,\n",
        "                                chaparral             = 6,\n",
        "                                church                = 7,\n",
        "                                circular_farmland     = 8,\n",
        "                                cloud                 = 9,\n",
        "                                commercial_area       = 10,\n",
        "                                dense_residential     = 11,\n",
        "                                desert                = 12,\n",
        "                                forest                = 13,\n",
        "                                freeway               = 14,\n",
        "                                golf_course           = 15,\n",
        "                                ground_track_field    = 16,\n",
        "                                harbor                = 17,\n",
        "                                industrial_area       = 18,\n",
        "                                intersection          = 19,\n",
        "                                island                = 20,\n",
        "                                lake                  = 21,\n",
        "                                meadow                = 22,\n",
        "                                medium_residential    = 23,\n",
        "                                mobile_home_park      = 24,\n",
        "                                mountain              = 25,\n",
        "                                overpass              = 26,\n",
        "                                palace                = 27,\n",
        "                                parking_lot           = 28,\n",
        "                                railway               = 29,\n",
        "                                railway_station       = 30,\n",
        "                                rectangular_farmland  = 31,\n",
        "                                river                 = 32,\n",
        "                                roundabout            = 33,\n",
        "                                runway                = 34,\n",
        "                                sea_ice               = 35,\n",
        "                                ship                  = 36,\n",
        "                                snowberg              = 37,\n",
        "                                sparse_residential    = 38,\n",
        "                                stadium               = 39,\n",
        "                                storage_tank          = 40,\n",
        "                                tennis_court          = 41,\n",
        "                                terrace               = 42,\n",
        "                                thermal_power_station = 43,\n",
        "                                wetland               = 44 )\n",
        "\n",
        "        #---- Para for generator and training\n",
        "    self.W             = 256   \n",
        "    self.H             = 256  \n",
        "    self.C             = 3    \n",
        "    self.batch_size    = 10  \n",
        "    self.learning_rate = 1e-4\n",
        "    self.check_every   = 200\n",
        "    self.class_num     = 45\n",
        "    self.epoch_num     = 273"
      ],
      "metadata": {
        "id": "-7R6cIM4yTtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generator_1.py"
      ],
      "metadata": {
        "id": "xIgVEzZGyts1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# from PIL import Image, ImageFilter, ImageEnhance\n",
        "\n",
        "# class SupervisedGenerator(object):\n",
        "#   def __init__(self, train_dir, test_dir, batch_size=6):  \n",
        "#     self.train_dir     = train_dir\n",
        "#     self.test_dir      = test_dir\n",
        "#     self.batch_size    = batch_size\n",
        "#     self.class_num     = hypara().class_num\n",
        "#     self.label_dict    = hypara().label_dict\n",
        "#     self.train_file_id = np.random.RandomState(seed=273).permutation(self.get_num_imgs(self.train_dir))\n",
        "#     self.test_file_id  = np.random.RandomState(seed=273).permutation(self.get_num_imgs(self.test_dir))\n",
        "\n",
        "#   def get_num_batch(self, is_train):\n",
        "#     if is_train == True:\n",
        "#       batch_total = self.get_num_imgs(self.train_dir) \n",
        "#     else:\n",
        "#       batch_total = self.get_num_imgs(self.test_dir) \n",
        "#     if batch_total % self.batch_size == 0:\n",
        "#       return (int(batch_total/self.batch_size), batch_total % self.batch_size) \n",
        "#     return (int(batch_total/self.batch_size) + 1, batch_total % self.batch_size) \n",
        "    \n",
        "#   def get_num_imgs(self, img_dir):\n",
        "#     return len(os.listdir(img_dir))\n",
        "  \n",
        "#   def get_file_list(self, is_train=True):\n",
        "#     if is_train == True:\n",
        "#       org_file_list = os.listdir(self.train_dir)\n",
        "#     else:\n",
        "#       org_file_list = os.listdir(self.test_dir)\n",
        "#     org_file_list.sort()\n",
        "#     return org_file_list\n",
        "\n",
        "#   def get_batch (self, batch_num, is_train=True): \n",
        "#     file_list = self.get_file_list(is_train) \n",
        "#     nImage = 0\n",
        "#     for ind in range(batch_num*self.batch_size, (batch_num+1)*self.batch_size):\n",
        "#       if is_train == True:\n",
        "#         file_name = file_list[self.train_file_id[ind]]\n",
        "#         file_open = os.path.join(self.train_dir, file_name)\n",
        "#       else:\n",
        "#         file_name = file_list[self.test_file_id[ind]]\n",
        "#         file_open = os.path.join(self.test_dir, file_name)\n",
        "\n",
        "#       #create label\n",
        "#       one_label  = np.zeros([1,self.class_num]) \n",
        "#       pattern    = file_name.split('_')[-1]         # airplane_000.jpg -> 000.jpg\n",
        "#       class_name = file_name.split('_'+pattern)[0]  \n",
        "#       nClass     = self.label_dict[class_name]\n",
        "#       one_label[0,nClass] = 1\n",
        "\n",
        "#       #create data\n",
        "#       one_image = Image.open(file_open)\n",
        "#       if is_train == True:  \n",
        "#         one_image = self.augmentate(one_image)\n",
        "#       one_image = np.asarray(one_image)\n",
        "#       [nW, nL, nC] = np.shape(one_image)\n",
        "#       one_image = np.reshape(one_image, (1,nW,nL,nC))\n",
        "\n",
        "#       if (nImage == 0):\n",
        "#         seq_x = one_image\n",
        "#         seq_y = one_label\n",
        "#       else:            \n",
        "#         seq_x = np.concatenate((seq_x, one_image), axis=0)  \n",
        "#         seq_y = np.concatenate((seq_y, one_label), axis=0)  \n",
        "#       nImage += 1\n",
        "    \n",
        "#     seq_x = tf.convert_to_tensor(seq_x, dtype=tf.float32)\n",
        "#     seq_y = tf.convert_to_tensor(seq_y, dtype=tf.float32)\n",
        "#     return seq_x, seq_y, nImage\n",
        "\n",
        "\n",
        "#   def augmentate(self, one_image): #---- data augmentation\n",
        "#     if np.random.uniform() > 0.5: # not augmentation\n",
        "#       return one_image\n",
        "\n",
        "#     if np.random.uniform() > 0.5: # rotate\n",
        "#       angle = random.choice([15,90,180,270])\n",
        "#       one_image  = one_image.rotate(angle)\n",
        "    \n",
        "#     if np.random.uniform() > 0.5: # crop\n",
        "#       rand = np.random.randint(0,15)\n",
        "#       one_image  = one_image.crop((rand,rand,256-rand,256-rand))\n",
        "#       one_image  = one_image.resize((256,256), resample=Image.BILINEAR)\n",
        "    \n",
        "#     rand = np.random.uniform()\n",
        "#     if rand > 0.5: # change color channel\n",
        "#       r, g, b = one_image.split()\n",
        "#       tup =  (b, r, g) if rand > 0.75 else (g, b, r)\n",
        "#       one_image = Image.merge(\"RGB\", tup)\n",
        "    \n",
        "#     if np.random.uniform() > 0.5: # change brightness\n",
        "#       one_image = one_image.point(lambda i: i * 1.27 if i*1.27 <= 255 else 255)\n",
        "    \n",
        "#     if np.random.uniform() > 0.5: # add noise\n",
        "#         one_image = one_image.point(lambda i: i + np.random.randint(-4,4)) \n",
        "\n",
        "#     rand = np.random.uniform() \n",
        "#     if rand > 0.75: # change contrast/sharpness/blur\n",
        "#       enhancer = ImageEnhance.Sharpness(one_image)\n",
        "#       one_image = enhancer.enhance(2.73)\n",
        "#     elif rand > 0.7: \n",
        "#       one_image = one_image.filter(ImageFilter.BLUR)\n",
        "#     elif rand > 0.45:\n",
        "#       enhancer = ImageEnhance.Contrast(one_image)\n",
        "#       one_image = enhancer.enhance(2.27)\n",
        "\n",
        "#     return one_image\n",
        "\n",
        "# train_dir = '/content/dataset/train/'\n",
        "# test_dir  = '/content/dataset/test/'\n",
        "# generator = SupervisedGenerator(train_dir=train_dir, test_dir=test_dir, batch_size=10)\n",
        "\n",
        "# print('train images: ', generator.get_num_imgs(train_dir))\n",
        "# print('test images: ', generator.get_num_imgs(test_dir))\n",
        "# print('train batches: ',generator.get_num_batch(is_train=True))\n",
        "# print('test batches: ',generator.get_num_batch(is_train=False))\n",
        "# print(generator.get_file_list(is_train=True)[:10])\n",
        "\n",
        "\n",
        "# x, y, n_imgs = generator.get_batch(batch_num=1, is_train=True)\n",
        "# print(x.shape,y.shape,n_imgs)"
      ],
      "metadata": {
        "id": "VAZ4yPkFyvm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img = Image.fromarray((x[0].numpy()).astype(np.uint8), 'RGB') # *255\n",
        "# img.show()\n",
        "# img = Image.fromarray((x[1].numpy()).astype(np.uint8), 'RGB')\n",
        "# img.show()\n",
        "# img = Image.fromarray((x[2].numpy()).astype(np.uint8), 'RGB')\n",
        "# img.show()\n",
        "# img = Image.fromarray((x[3].numpy()).astype(np.uint8), 'RGB')\n",
        "# img.show()\n",
        "# img = Image.fromarray((x[4].numpy()).astype(np.uint8), 'RGB')\n",
        "# img.show()\n",
        "\n",
        "# del img, x, y, generator, train_dir, test_dir, n_imgs"
      ],
      "metadata": {
        "id": "-xsX_Arqy5NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generator_2.py"
      ],
      "metadata": {
        "id": "Dcswqrt8yclI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFilter, ImageEnhance\n",
        "\n",
        "class SupervisedGenerator2(object):\n",
        "  def __init__(self, train_dir, test_dir):  \n",
        "    self.train_dir     = train_dir\n",
        "    self.test_dir      = test_dir\n",
        "    self.class_num     = hypara().class_num\n",
        "    self.label_dict    = hypara().label_dict\n",
        "\n",
        "  def get_num_classes(self, is_train=True):\n",
        "    if is_train:\n",
        "      return len(os.listdir(self.train_dir))\n",
        "    return len(os.listdir(self.test_dir))\n",
        "\n",
        "  def get_imgs_of_class(self, cls, is_train=True):\n",
        "    if is_train:\n",
        "      file_list = os.listdir(os.path.join(self.train_dir, cls))\n",
        "    else:\n",
        "      file_list = os.listdir(os.path.join(self.test_dir, cls))\n",
        "    file_list.sort()\n",
        "    return file_list\n",
        "\n",
        "  def get_batch (self, idx_num, class_list, is_train=True, is_aug=True): \n",
        "    if self.class_num != len(class_list):\n",
        "      raise ValueError('batch_size != 45')\n",
        "\n",
        "    if is_train == True:\n",
        "      img_dir = self.train_dir\n",
        "    else:\n",
        "      img_dir = self.test_dir\n",
        "    \n",
        "    nImage = 0\n",
        "    for c in class_list: # class_list can be considered as batch_size\n",
        "      file_path   = os.path.join(img_dir, c)\n",
        "      file_list   = self.get_imgs_of_class(c,is_train)\n",
        "      file_name   = file_list[idx_num]\n",
        "      file_open   = os.path.join(file_path, file_name)\n",
        "\n",
        "      #create label\n",
        "      one_label   = np.zeros([1,self.class_num]) \n",
        "      pattern     = file_name.split('_')[-1]         # airplane_000.jpg -> 000.jpg\n",
        "      class_name  = file_name.split('_'+pattern)[0]  \n",
        "      nClass      = self.label_dict[class_name]\n",
        "      one_label[0,nClass] = 1\n",
        "\n",
        "      #create data\n",
        "      one_image = Image.open(file_open)\n",
        "      if (is_train == True) and (is_aug == True):  \n",
        "        one_image = self.augmentate(one_image)\n",
        "      one_image    = np.asarray(one_image)\n",
        "      [nW, nL, nC] = np.shape(one_image)\n",
        "      one_image    = np.reshape(one_image, (1,nW,nL,nC))\n",
        "\n",
        "      if (nImage == 0):\n",
        "        seq_x = one_image\n",
        "        seq_y = one_label\n",
        "      else:            \n",
        "        seq_x = np.concatenate((seq_x, one_image), axis=0)  \n",
        "        seq_y = np.concatenate((seq_y, one_label), axis=0)  \n",
        "      nImage += 1\n",
        "    \n",
        "    seq_x = tf.convert_to_tensor(seq_x, dtype=tf.float32)\n",
        "    seq_y = tf.convert_to_tensor(seq_y, dtype=tf.float32)\n",
        "    return seq_x, seq_y, nImage\n",
        "\n",
        "  def augmentate(self, one_image): #---- data augmentation\n",
        "    if np.random.uniform() > 0.5: # not augmentation\n",
        "      return one_image\n",
        "\n",
        "    if np.random.uniform() > 0.5: # rotate\n",
        "      angle = random.choice([15,90,180,270])\n",
        "      one_image  = one_image.rotate(angle)\n",
        "    \n",
        "    if np.random.uniform() > 0.5: # crop\n",
        "      rand = np.random.randint(0,15)\n",
        "      one_image  = one_image.crop((rand,rand,256-rand,256-rand))\n",
        "      one_image  = one_image.resize((256,256), resample=Image.BILINEAR)\n",
        "    \n",
        "    rand = np.random.uniform()\n",
        "    if rand > 0.5: # change color channel\n",
        "      r, g, b = one_image.split()\n",
        "      tup =  (b, r, g) if rand > 0.75 else (g, b, r)\n",
        "      one_image = Image.merge(\"RGB\", tup)\n",
        "    \n",
        "    if np.random.uniform() > 0.5: # change brightness\n",
        "      one_image = one_image.point(lambda i: i * 1.2 if i*1.2 <= 255 else 255)\n",
        "    \n",
        "    if np.random.uniform() > 0.5: # add noise\n",
        "        one_image = one_image.point(lambda i: i + np.random.randint(-4,4)) \n",
        "\n",
        "    rand = np.random.uniform() \n",
        "    if rand > 0.75: # change contrast/sharpness/blur\n",
        "      enhancer = ImageEnhance.Sharpness(one_image)\n",
        "      one_image = enhancer.enhance(2.73)\n",
        "    elif rand > 0.7: \n",
        "      one_image = one_image.filter(ImageFilter.BLUR)\n",
        "    elif rand > 0.45:\n",
        "      enhancer = ImageEnhance.Contrast(one_image)\n",
        "      one_image = enhancer.enhance(2.27)\n",
        "\n",
        "    return one_image\n",
        "\n",
        "train_dir  = '/content/dataset2/train/'\n",
        "test_dir   = '/content/dataset2/test/'\n",
        "generator  = SupervisedGenerator2(train_dir=train_dir, test_dir=test_dir)\n",
        "label_dict = hypara().label_dict\n",
        "class_list = list(label_dict.keys())\n",
        "\n",
        "print('train classes: ', generator.get_num_classes(train_dir))\n",
        "print('test classes: ', generator.get_num_classes(test_dir))\n",
        "print('class_list:', class_list)\n",
        "print('some imgs: ', len(generator.get_imgs_of_class(class_list[0],is_train=True)), generator.get_imgs_of_class(class_list[0],is_train=True)[0],generator.get_imgs_of_class(class_list[0],is_train=True)[-1])\n",
        "x, y, n_imgs = generator.get_batch(idx_num=0, class_list=class_list, is_train=True)\n",
        "print(x.shape,y.shape,n_imgs)"
      ],
      "metadata": {
        "id": "Pm63PD96ylhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.fromarray((x[0].numpy()).astype(np.uint8), 'RGB') # *255\n",
        "img.show()\n",
        "img = Image.fromarray((x[1].numpy()).astype(np.uint8), 'RGB')\n",
        "img.show()\n",
        "img = Image.fromarray((x[2].numpy()).astype(np.uint8), 'RGB')\n",
        "img.show()\n",
        "img = Image.fromarray((x[3].numpy()).astype(np.uint8), 'RGB')\n",
        "img.show()\n",
        "img = Image.fromarray((x[4].numpy()).astype(np.uint8), 'RGB')\n",
        "img.show()\n",
        "\n",
        "del img, x, y, generator, train_dir, test_dir, n_imgs,class_list,label_dict"
      ],
      "metadata": {
        "id": "cMwCvA4vyyhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train classification model - Phase 2"
      ],
      "metadata": {
        "id": "KccJG5vuyy1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train.py (1)"
      ],
      "metadata": {
        "id": "VxnTVEuazNyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# from datetime import datetime\n",
        "\n",
        "# def lr_schedule(epoch, lr):\n",
        "#   if epoch < 4:\n",
        "#     return 5e-4\n",
        "#   elif (epoch <= 68) and (epoch % 4 == 0):\n",
        "#     return lr * 0.9 \n",
        "#   elif epoch > 68:\n",
        "#     return 4e-5\n",
        "#   else:\n",
        "#     return lr\n",
        "\n",
        "# stored_dir      = '/content/drive/MyDrive/RSIC/NWPU-RESISC45/effb0_567_contrastive'\n",
        "# best_model_file = '/content/drive/MyDrive/RSIC/NWPU-RESISC45/effb0_567_contrastive/contrastive_model.h5'\n",
        "# train_dir       = '/content/dataset/train/'\n",
        "# test_dir        = '/content/dataset/test/'\n",
        "# generator       = SupervisedGenerator(train_dir=train_dir, test_dir=test_dir, batch_size=45) # 18\n",
        "\n",
        "# batch_train, img_train_left      = generator.get_num_batch(is_train=True)\n",
        "# batch_test,  img_test_left       = generator.get_num_batch(is_train=False)\n",
        "# print('total batch train: ' ,batch_train, ';     total batch test: ', batch_test)\n",
        "# print('img_train_left: ' ,img_train_left, ';     img_test_left: ', img_test_left)\n",
        "# print(train_dir)\n",
        "# print(test_dir)\n",
        "# print(stored_dir)\n",
        "\n",
        "# old_test_acc  = 0\n",
        "# current_epoch = 5\n",
        "\n",
        "# for epoch in range(current_epoch, 273):\n",
        "#   print(\"\\n\\n=======================  Epoch-\", epoch, \" ============================\")\n",
        "#   start_epoch = datetime.now()\n",
        "#   epoch_acc = 0\n",
        "#   model.optimizer.learning_rate = lr_schedule(epoch, model.optimizer.learning_rate.numpy())\n",
        "#   print('# current_learning_rate: ', model.optimizer.learning_rate)\n",
        "#   print('-------- training ---------')\n",
        "#   for n_batch_train in range(batch_train):\n",
        "#     x_train_batch, y_train_batch, n_image = generator.get_batch(batch_num=n_batch_train, is_train=True) \n",
        "#     [train_loss, train_acc] = model.train_on_batch(x_train_batch, y_train_batch, reset_metrics=True)\n",
        "#     epoch_acc += train_acc\n",
        "    \n",
        "#     if n_batch_train == (batch_train-1) and epoch >= 5: \n",
        "#       print(\"------ testing -------\")\n",
        "#       start_test = datetime.now()\n",
        "#       test_acc_avg = 0\n",
        "#       for n_batch_test in range(0, batch_test):\n",
        "#         x_test_batch, y_test_batch, n_image = generator.get_batch(batch_num=n_batch_test, is_train=False)\n",
        "#         [test_loss, test_acc] = model.evaluate(x_test_batch, y_test_batch, verbose=0)\n",
        "#         test_acc_avg += test_acc\n",
        "\n",
        "#       test_acc_avg /= batch_test\n",
        "#       print('test accuray: ', test_acc_avg, '  and time needed for test: ', datetime.now()-start_test)\n",
        "\n",
        "#       # Save model when successfully testing\n",
        "#       if (test_acc_avg > old_test_acc):\n",
        "#         old_test_acc = test_acc_avg \n",
        "#         model.save(best_model_file)\n",
        "#         print('Save model completed')\n",
        "#         with open(os.path.join(stored_dir,\"train_log.txt\"), \"a\") as text_file:\n",
        "#           text_file.write(\"Save best model at Epoch: {}; Accuracy: {}\\n\".format(epoch, old_test_acc))\n",
        "\n",
        "#   with open(os.path.join(stored_dir,\"train_log.txt\"), \"a\") as text_file:\n",
        "#     text_file.write(\"Epoch: {}; lr: {}; Train accuracy: {}\\n\".format(epoch, model.optimizer.learning_rate.numpy(), epoch_acc/batch_train))\n",
        "#   print('# Epoch training accuracy: ', epoch_acc/batch_train)\n",
        "#   print('# Time needed for train 1 epoch', datetime.now()-start_epoch)"
      ],
      "metadata": {
        "id": "WLzashl_zQYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train.py (2)"
      ],
      "metadata": {
        "id": "HBPASdnfzLV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "  if epoch < 4:\n",
        "    return 5e-4\n",
        "  elif (epoch <= 72) and (epoch % 4 == 0):\n",
        "    return lr * 0.9 \n",
        "  elif epoch < 95:\n",
        "    return 4e-5\n",
        "  elif epoch < 111:\n",
        "    return 1e-5\n",
        "  elif epoch < 160:\n",
        "    return 4e-6\n",
        "  elif epoch < 227:\n",
        "    return 1e-6\n",
        "  elif epoch < 273:\n",
        "    return 2.27e-7\n",
        "  elif epoch < 283:\n",
        "    return 1e-7\n",
        "  else:\n",
        "    return lr\n",
        "\n",
        "stored_dir      = '/content/drive/MyDrive/RSIC/NWPU-RESISC45/effb0_contrastive_2'\n",
        "best_model_file = '/content/drive/MyDrive/RSIC/NWPU-RESISC45/effb0_contrastive_2/contrastive_model.h5'\n",
        "train_dir       = '/content/dataset2/train/'\n",
        "test_dir        = '/content/dataset2/test/'\n",
        "label_dict      = hypara().label_dict\n",
        "class_list      = list(label_dict.keys())\n",
        "batch_train     = int(6300/45)\n",
        "batch_test      = int(25200/45)\n",
        "generator       = SupervisedGenerator2(train_dir=train_dir, test_dir=test_dir)\n",
        "\n",
        "print('total batch train: ' ,6300/45, ';     total batch test: ', 25200/45)\n",
        "print(train_dir)\n",
        "print(test_dir)\n",
        "print(stored_dir)\n",
        "\n",
        "old_test_acc  = 0.9288492106\n",
        "current_epoch = 273\n",
        "\n",
        "for epoch in range(current_epoch, 283):\n",
        "  print(\"\\n\\n=======================  Epoch-\", epoch, \" ============================\")\n",
        "  start_epoch = datetime.now()\n",
        "  epoch_acc = 0\n",
        "  if epoch == current_epoch:\n",
        "    model.optimizer.learning_rate = 1e-7\n",
        "  else:\n",
        "    model.optimizer.learning_rate = lr_schedule(epoch, model.optimizer.learning_rate.numpy())\n",
        "  print('# current_learning_rate: ', model.optimizer.learning_rate)\n",
        "  print('-------- training ---------')\n",
        "  for n_batch_train in range(batch_train):\n",
        "    if epoch >= 273:\n",
        "      is_aug = False\n",
        "    else:\n",
        "      is_aug = True\n",
        "    x_train_batch, y_train_batch, n_image = generator.get_batch(idx_num=n_batch_train, class_list=class_list, is_train=True, is_aug=is_aug) \n",
        "    [train_loss, train_acc] = model.train_on_batch(x_train_batch, y_train_batch, reset_metrics=True)\n",
        "    epoch_acc += train_acc\n",
        "    \n",
        "    if n_batch_train == 139 and epoch >= 4: \n",
        "      print(\"------ testing -------\")\n",
        "      start_test = datetime.now()\n",
        "      test_acc_avg = 0\n",
        "      for n_batch_test in range(batch_test):\n",
        "        x_test_batch, y_test_batch, n_image = generator.get_batch(idx_num=n_batch_test, class_list=class_list, is_train=False, is_aug=False)\n",
        "        [test_loss, test_acc] = model.evaluate(x_test_batch, y_test_batch, verbose=0)\n",
        "        test_acc_avg += test_acc\n",
        "\n",
        "      test_acc_avg /= batch_test\n",
        "      print('test accuray: ', test_acc_avg, '  and time needed for test: ', datetime.now()-start_test)\n",
        "\n",
        "      # Save model when successfully testing\n",
        "      if (test_acc_avg > old_test_acc):\n",
        "        old_test_acc = test_acc_avg \n",
        "        model.save(best_model_file)\n",
        "        print('Save model completed')\n",
        "        with open(os.path.join(stored_dir,\"train_log.txt\"), \"a\") as text_file:\n",
        "          text_file.write(\"Save best model at Epoch: {}; Accuracy: {}\\n\".format(epoch, old_test_acc))\n",
        "\n",
        "  with open(os.path.join(stored_dir,\"train_log.txt\"), \"a\") as text_file:\n",
        "    text_file.write(\"Epoch: {}; lr: {}; Train accuracy: {}\\n\".format(epoch, model.optimizer.learning_rate.numpy(), epoch_acc/batch_train))\n",
        "  print('# Epoch training accuracy: ', epoch_acc/batch_train)\n",
        "  print('# Time needed for train 1 epoch', datetime.now()-start_epoch)"
      ],
      "metadata": {
        "id": "Q7H2cJb1zIdR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}